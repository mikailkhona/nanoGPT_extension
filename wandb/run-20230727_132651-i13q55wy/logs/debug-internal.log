2023-07-27 13:26:51,762 INFO    StreamThr :20550 [internal.py:wandb_internal():86] W&B internal server running at pid: 20550, started at: 2023-07-27 13:26:51.761669
2023-07-27 13:26:51,763 DEBUG   HandlerThread:20550 [handler.py:handle_request():144] handle_request: status
2023-07-27 13:26:51,764 INFO    WriterThread:20550 [datastore.py:open_for_write():85] open: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/run-i13q55wy.wandb
2023-07-27 13:26:51,765 DEBUG   SenderThread:20550 [sender.py:send():379] send: header
2023-07-27 13:26:51,766 DEBUG   SenderThread:20550 [sender.py:send():379] send: run
2023-07-27 13:26:52,012 INFO    SenderThread:20550 [dir_watcher.py:__init__():211] watching files in: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/files
2023-07-27 13:26:52,012 INFO    SenderThread:20550 [sender.py:_start_run_threads():1122] run started: i13q55wy with start time 1690478811.761274
2023-07-27 13:26:52,014 DEBUG   SenderThread:20550 [sender.py:send_request():406] send_request: summary_record
2023-07-27 13:26:52,014 INFO    SenderThread:20550 [sender.py:_save_file():1376] saving file wandb-summary.json with policy end
2023-07-27 13:26:52,024 DEBUG   HandlerThread:20550 [handler.py:handle_request():144] handle_request: check_version
2023-07-27 13:26:52,025 DEBUG   SenderThread:20550 [sender.py:send_request():406] send_request: check_version
2023-07-27 13:26:52,326 DEBUG   HandlerThread:20550 [handler.py:handle_request():144] handle_request: run_start
2023-07-27 13:26:52,330 DEBUG   HandlerThread:20550 [system_info.py:__init__():31] System info init
2023-07-27 13:26:52,330 DEBUG   HandlerThread:20550 [system_info.py:__init__():46] System info init done
2023-07-27 13:26:52,330 INFO    HandlerThread:20550 [system_monitor.py:start():181] Starting system monitor
2023-07-27 13:26:52,330 INFO    SystemMonitor:20550 [system_monitor.py:_start():145] Starting system asset monitoring threads
2023-07-27 13:26:52,331 INFO    HandlerThread:20550 [system_monitor.py:probe():201] Collecting system info
2023-07-27 13:26:52,332 INFO    SystemMonitor:20550 [interfaces.py:start():190] Started cpu monitoring
2023-07-27 13:26:52,332 INFO    SystemMonitor:20550 [interfaces.py:start():190] Started disk monitoring
2023-07-27 13:26:52,333 INFO    SystemMonitor:20550 [interfaces.py:start():190] Started gpu monitoring
2023-07-27 13:26:52,333 INFO    SystemMonitor:20550 [interfaces.py:start():190] Started memory monitoring
2023-07-27 13:26:52,333 INFO    SystemMonitor:20550 [interfaces.py:start():190] Started network monitoring
2023-07-27 13:26:52,367 DEBUG   HandlerThread:20550 [system_info.py:probe():195] Probing system
2023-07-27 13:26:52,369 DEBUG   HandlerThread:20550 [system_info.py:_probe_git():180] Probing git
2023-07-27 13:26:52,375 DEBUG   HandlerThread:20550 [system_info.py:_probe_git():188] Probing git done
2023-07-27 13:26:52,375 DEBUG   HandlerThread:20550 [system_info.py:probe():240] Probing system done
2023-07-27 13:26:52,375 DEBUG   HandlerThread:20550 [system_monitor.py:probe():210] {'os': 'Linux-5.19.0-46-generic-x86_64-with-glibc2.35', 'python': '3.10.6', 'heartbeatAt': '2023-07-27T17:26:52.367678', 'startedAt': '2023-07-27T17:26:51.757388', 'docker': None, 'cuda': None, 'args': (), 'state': 'running', 'program': '/home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/train_ntt.py', 'codePath': 'train_ntt.py', 'git': {'remote': 'git@github.com:mikailkhona/nanoGPT_extension.git', 'commit': 'd6d0d4b745baefa89392e7c8db5f729ac2e1bc4d'}, 'email': None, 'root': '/home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension', 'host': 'dl', 'username': 'bizon', 'executable': '/usr/bin/python3', 'cpu_count': 32, 'cpu_count_logical': 64, 'cpu_freq': {'current': 2.1153281249999996, 'min': 1800.0, 'max': 3600.0}, 'cpu_freq_per_core': [{'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.797, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.798, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.818, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.808, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 2.14, 'min': 1800.0, 'max': 3600.0}, {'current': 1.889, 'min': 1800.0, 'max': 3600.0}, {'current': 1.872, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.843, 'min': 1800.0, 'max': 3600.0}, {'current': 1.798, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.798, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.793, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.797, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 2.399, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.917, 'min': 1800.0, 'max': 3600.0}, {'current': 1.843, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.918, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 2.011, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.873, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 2.241, 'min': 1800.0, 'max': 3600.0}, {'current': 2.399, 'min': 1800.0, 'max': 3600.0}, {'current': 1.919, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}], 'disk': {'total': 1876.1108436584473, 'used': 587.645378112793}, 'gpu': 'NVIDIA RTX A6000', 'gpu_count': 6, 'gpu_devices': [{'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}], 'memory': {'total': 503.52610778808594}}
2023-07-27 13:26:52,375 INFO    HandlerThread:20550 [system_monitor.py:probe():211] Finished collecting system info
2023-07-27 13:26:52,375 INFO    HandlerThread:20550 [system_monitor.py:probe():214] Publishing system info
2023-07-27 13:26:52,375 DEBUG   HandlerThread:20550 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment
2023-07-27 13:26:52,376 DEBUG   HandlerThread:20550 [system_info.py:_save_pip():67] Saving pip packages done
2023-07-27 13:26:52,376 INFO    HandlerThread:20550 [system_monitor.py:probe():216] Finished publishing system info
2023-07-27 13:26:53,015 INFO    Thread-12 :20550 [dir_watcher.py:_on_file_created():272] file/dir created: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/files/requirements.txt
2023-07-27 13:26:53,015 INFO    Thread-12 :20550 [dir_watcher.py:_on_file_created():272] file/dir created: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/files/wandb-summary.json
2023-07-27 13:26:53,015 INFO    Thread-12 :20550 [dir_watcher.py:_on_file_created():272] file/dir created: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/files/wandb-metadata.json
2023-07-27 13:26:53,025 INFO    WriterThread:20550 [datastore.py:close():294] close: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/run-i13q55wy.wandb
2023-07-27 13:26:53,320 INFO    SenderThread:20550 [sender.py:finish():1552] shutting down sender
2023-07-27 13:26:53,320 INFO    SenderThread:20550 [dir_watcher.py:finish():359] shutting down directory watcher
2023-07-27 13:26:54,016 INFO    SenderThread:20550 [dir_watcher.py:finish():389] scan: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/files
2023-07-27 13:26:54,016 INFO    SenderThread:20550 [dir_watcher.py:finish():403] scan save: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/files/wandb-summary.json wandb-summary.json
2023-07-27 13:26:54,017 INFO    SenderThread:20550 [dir_watcher.py:finish():403] scan save: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/files/wandb-metadata.json wandb-metadata.json
2023-07-27 13:26:54,017 INFO    SenderThread:20550 [dir_watcher.py:finish():403] scan save: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/files/config.yaml config.yaml
2023-07-27 13:26:54,020 INFO    SenderThread:20550 [dir_watcher.py:finish():403] scan save: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/files/requirements.txt requirements.txt
2023-07-27 13:26:54,020 INFO    SenderThread:20550 [file_pusher.py:finish():159] shutting down file pusher
2023-07-27 13:26:54,020 INFO    SenderThread:20550 [file_pusher.py:join():164] waiting for file pusher
2023-07-27 13:26:54,519 INFO    wandb-upload_0:20550 [upload_job.py:push():131] Uploaded file /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/files/wandb-summary.json
2023-07-27 13:26:54,602 INFO    wandb-upload_3:20550 [upload_job.py:push():131] Uploaded file /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/files/requirements.txt
2023-07-27 13:26:54,682 INFO    wandb-upload_1:20550 [upload_job.py:push():131] Uploaded file /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/files/wandb-metadata.json
2023-07-27 13:26:54,684 INFO    wandb-upload_2:20550 [upload_job.py:push():131] Uploaded file /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_132651-i13q55wy/files/config.yaml
2023-07-27 13:26:55,183 ERROR   StreamThr :20550 [internal.py:wandb_internal():174] Thread HandlerThread:
Traceback (most recent call last):
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py", line 49, in run
    self._run()
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py", line 100, in _run
    self._process(record)
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal.py", line 279, in _process
    self._hm.handle(record)
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/handler.py", line 136, in handle
    handler(record)
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/handler.py", line 146, in handle_request
    handler(record)
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/handler.py", line 708, in handle_request_run_start
    self._tb_watcher = tb_watcher.TBWatcher(
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/tb_watcher.py", line 126, in __init__
    wandb.tensorboard.reset_state()
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/lib/lazyloader.py", line 58, in __getattr__
    module = self._load()
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/lib/lazyloader.py", line 33, in _load
    module = importlib.import_module(self.__name__)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/integration/tensorboard/__init__.py", line 3, in <module>
    from .log import _log, log, reset_state, tf_summary_to_dict  # noqa: F401
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/integration/tensorboard/log.py", line 35, in <module>
    Summary = pb.Summary if pb else None
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/util.py", line 204, in __getattribute__
    state.load()
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/util.py", line 197, in load
    self.module.__spec__.loader.exec_module(self.module)
  File "/usr/local/lib/python3.10/dist-packages/tensorboard/compat/proto/summary_pb2.py", line 17, in <module>
    from tensorboard.compat.proto import tensor_pb2 as tensorboard_dot_compat_dot_proto_dot_tensor__pb2
  File "/usr/local/lib/python3.10/dist-packages/tensorboard/compat/proto/tensor_pb2.py", line 16, in <module>
    from tensorboard.compat.proto import resource_handle_pb2 as tensorboard_dot_compat_dot_proto_dot_resource__handle__pb2
  File "/usr/local/lib/python3.10/dist-packages/tensorboard/compat/proto/resource_handle_pb2.py", line 16, in <module>
    from tensorboard.compat.proto import tensor_shape_pb2 as tensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2
  File "/usr/local/lib/python3.10/dist-packages/tensorboard/compat/proto/tensor_shape_pb2.py", line 36, in <module>
    _descriptor.FieldDescriptor(
  File "/home/bizon/.local/lib/python3.10/site-packages/google/protobuf/descriptor.py", line 561, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot not be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates
