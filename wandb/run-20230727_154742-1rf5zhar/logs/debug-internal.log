2023-07-27 15:47:42,098 INFO    StreamThr :40475 [internal.py:wandb_internal():86] W&B internal server running at pid: 40475, started at: 2023-07-27 15:47:42.098030
2023-07-27 15:47:42,099 DEBUG   HandlerThread:40475 [handler.py:handle_request():144] handle_request: status
2023-07-27 15:47:42,101 INFO    WriterThread:40475 [datastore.py:open_for_write():85] open: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/run-1rf5zhar.wandb
2023-07-27 15:47:42,101 DEBUG   SenderThread:40475 [sender.py:send():379] send: header
2023-07-27 15:47:42,102 DEBUG   SenderThread:40475 [sender.py:send():379] send: run
2023-07-27 15:47:42,336 INFO    SenderThread:40475 [dir_watcher.py:__init__():211] watching files in: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/files
2023-07-27 15:47:42,336 INFO    SenderThread:40475 [sender.py:_start_run_threads():1122] run started: 1rf5zhar with start time 1690487262.097676
2023-07-27 15:47:42,336 DEBUG   SenderThread:40475 [sender.py:send_request():406] send_request: summary_record
2023-07-27 15:47:42,336 INFO    SenderThread:40475 [sender.py:_save_file():1376] saving file wandb-summary.json with policy end
2023-07-27 15:47:42,339 DEBUG   HandlerThread:40475 [handler.py:handle_request():144] handle_request: check_version
2023-07-27 15:47:42,340 DEBUG   SenderThread:40475 [sender.py:send_request():406] send_request: check_version
2023-07-27 15:47:42,425 DEBUG   HandlerThread:40475 [handler.py:handle_request():144] handle_request: run_start
2023-07-27 15:47:42,429 DEBUG   HandlerThread:40475 [system_info.py:__init__():31] System info init
2023-07-27 15:47:42,429 DEBUG   HandlerThread:40475 [system_info.py:__init__():46] System info init done
2023-07-27 15:47:42,430 INFO    HandlerThread:40475 [system_monitor.py:start():181] Starting system monitor
2023-07-27 15:47:42,430 INFO    SystemMonitor:40475 [system_monitor.py:_start():145] Starting system asset monitoring threads
2023-07-27 15:47:42,430 INFO    HandlerThread:40475 [system_monitor.py:probe():201] Collecting system info
2023-07-27 15:47:42,431 INFO    SystemMonitor:40475 [interfaces.py:start():190] Started cpu monitoring
2023-07-27 15:47:42,431 INFO    SystemMonitor:40475 [interfaces.py:start():190] Started disk monitoring
2023-07-27 15:47:42,432 INFO    SystemMonitor:40475 [interfaces.py:start():190] Started gpu monitoring
2023-07-27 15:47:42,432 INFO    SystemMonitor:40475 [interfaces.py:start():190] Started memory monitoring
2023-07-27 15:47:42,432 INFO    SystemMonitor:40475 [interfaces.py:start():190] Started network monitoring
2023-07-27 15:47:42,469 DEBUG   HandlerThread:40475 [system_info.py:probe():195] Probing system
2023-07-27 15:47:42,471 DEBUG   HandlerThread:40475 [system_info.py:_probe_git():180] Probing git
2023-07-27 15:47:42,476 DEBUG   HandlerThread:40475 [system_info.py:_probe_git():188] Probing git done
2023-07-27 15:47:42,476 DEBUG   HandlerThread:40475 [system_info.py:probe():240] Probing system done
2023-07-27 15:47:42,476 DEBUG   HandlerThread:40475 [system_monitor.py:probe():210] {'os': 'Linux-5.19.0-46-generic-x86_64-with-glibc2.35', 'python': '3.10.6', 'heartbeatAt': '2023-07-27T19:47:42.469344', 'startedAt': '2023-07-27T19:47:42.094670', 'docker': None, 'cuda': None, 'args': (), 'state': 'running', 'program': '/home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/train_ntt.py', 'codePath': 'train_ntt.py', 'git': {'remote': 'git@github.com:mikailkhona/nanoGPT_extension.git', 'commit': '3c37b9ebbfdc87ddf7061f3ae7247b090ad2a058'}, 'email': 'mikailkhona@gmail.com', 'root': '/home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension', 'host': 'dl', 'username': 'bizon', 'executable': '/usr/bin/python3', 'cpu_count': 32, 'cpu_count_logical': 64, 'cpu_freq': {'current': 2.4825781250000003, 'min': 1800.0, 'max': 3600.0}, 'cpu_freq_per_core': [{'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.87, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.263, 'min': 1800.0, 'max': 3600.0}, {'current': 1.942, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.631, 'min': 1800.0, 'max': 3600.0}, {'current': 4.323, 'min': 1800.0, 'max': 3600.0}, {'current': 4.366, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 2.776, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.798, 'min': 1800.0, 'max': 3600.0}, {'current': 2.93, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 4.326, 'min': 1800.0, 'max': 3600.0}, {'current': 4.455, 'min': 1800.0, 'max': 3600.0}, {'current': 3.495, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}], 'disk': {'total': 1876.1108436584473, 'used': 590.0022163391113}, 'gpu': 'NVIDIA RTX A6000', 'gpu_count': 6, 'gpu_devices': [{'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}], 'memory': {'total': 503.52610778808594}}
2023-07-27 15:47:42,476 INFO    HandlerThread:40475 [system_monitor.py:probe():211] Finished collecting system info
2023-07-27 15:47:42,476 INFO    HandlerThread:40475 [system_monitor.py:probe():214] Publishing system info
2023-07-27 15:47:42,476 DEBUG   HandlerThread:40475 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment
2023-07-27 15:47:42,477 DEBUG   HandlerThread:40475 [system_info.py:_save_pip():67] Saving pip packages done
2023-07-27 15:47:42,477 INFO    HandlerThread:40475 [system_monitor.py:probe():216] Finished publishing system info
2023-07-27 15:47:43,338 INFO    Thread-12 :40475 [dir_watcher.py:_on_file_created():272] file/dir created: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/files/wandb-metadata.json
2023-07-27 15:47:43,338 INFO    Thread-12 :40475 [dir_watcher.py:_on_file_created():272] file/dir created: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/files/wandb-summary.json
2023-07-27 15:47:43,339 INFO    Thread-12 :40475 [dir_watcher.py:_on_file_created():272] file/dir created: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/files/requirements.txt
2023-07-27 15:47:43,340 INFO    WriterThread:40475 [datastore.py:close():294] close: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/run-1rf5zhar.wandb
2023-07-27 15:47:43,422 INFO    SenderThread:40475 [sender.py:finish():1552] shutting down sender
2023-07-27 15:47:43,423 INFO    SenderThread:40475 [dir_watcher.py:finish():359] shutting down directory watcher
2023-07-27 15:47:44,339 INFO    SenderThread:40475 [dir_watcher.py:finish():389] scan: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/files
2023-07-27 15:47:44,340 INFO    SenderThread:40475 [dir_watcher.py:finish():403] scan save: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/files/wandb-summary.json wandb-summary.json
2023-07-27 15:47:44,340 INFO    SenderThread:40475 [dir_watcher.py:finish():403] scan save: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/files/wandb-metadata.json wandb-metadata.json
2023-07-27 15:47:44,340 INFO    SenderThread:40475 [dir_watcher.py:finish():403] scan save: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/files/config.yaml config.yaml
2023-07-27 15:47:44,340 INFO    SenderThread:40475 [dir_watcher.py:finish():403] scan save: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/files/requirements.txt requirements.txt
2023-07-27 15:47:44,340 INFO    SenderThread:40475 [file_pusher.py:finish():159] shutting down file pusher
2023-07-27 15:47:44,340 INFO    SenderThread:40475 [file_pusher.py:join():164] waiting for file pusher
2023-07-27 15:47:44,924 INFO    wandb-upload_1:40475 [upload_job.py:push():131] Uploaded file /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/files/wandb-metadata.json
2023-07-27 15:47:45,007 INFO    wandb-upload_0:40475 [upload_job.py:push():131] Uploaded file /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/files/wandb-summary.json
2023-07-27 15:47:45,008 INFO    wandb-upload_2:40475 [upload_job.py:push():131] Uploaded file /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/files/config.yaml
2023-07-27 15:47:45,038 INFO    wandb-upload_3:40475 [upload_job.py:push():131] Uploaded file /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_154742-1rf5zhar/files/requirements.txt
2023-07-27 15:47:45,514 ERROR   StreamThr :40475 [internal.py:wandb_internal():174] Thread HandlerThread:
Traceback (most recent call last):
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py", line 49, in run
    self._run()
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py", line 100, in _run
    self._process(record)
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal.py", line 279, in _process
    self._hm.handle(record)
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/handler.py", line 136, in handle
    handler(record)
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/handler.py", line 146, in handle_request
    handler(record)
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/handler.py", line 708, in handle_request_run_start
    self._tb_watcher = tb_watcher.TBWatcher(
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/tb_watcher.py", line 126, in __init__
    wandb.tensorboard.reset_state()
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/lib/lazyloader.py", line 58, in __getattr__
    module = self._load()
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/lib/lazyloader.py", line 33, in _load
    module = importlib.import_module(self.__name__)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/integration/tensorboard/__init__.py", line 3, in <module>
    from .log import _log, log, reset_state, tf_summary_to_dict  # noqa: F401
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/integration/tensorboard/log.py", line 35, in <module>
    Summary = pb.Summary if pb else None
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/util.py", line 204, in __getattribute__
    state.load()
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/util.py", line 197, in load
    self.module.__spec__.loader.exec_module(self.module)
  File "/usr/local/lib/python3.10/dist-packages/tensorboard/compat/proto/summary_pb2.py", line 17, in <module>
    from tensorboard.compat.proto import tensor_pb2 as tensorboard_dot_compat_dot_proto_dot_tensor__pb2
  File "/usr/local/lib/python3.10/dist-packages/tensorboard/compat/proto/tensor_pb2.py", line 16, in <module>
    from tensorboard.compat.proto import resource_handle_pb2 as tensorboard_dot_compat_dot_proto_dot_resource__handle__pb2
  File "/usr/local/lib/python3.10/dist-packages/tensorboard/compat/proto/resource_handle_pb2.py", line 16, in <module>
    from tensorboard.compat.proto import tensor_shape_pb2 as tensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2
  File "/usr/local/lib/python3.10/dist-packages/tensorboard/compat/proto/tensor_shape_pb2.py", line 36, in <module>
    _descriptor.FieldDescriptor(
  File "/home/bizon/.local/lib/python3.10/site-packages/google/protobuf/descriptor.py", line 561, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot not be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates
