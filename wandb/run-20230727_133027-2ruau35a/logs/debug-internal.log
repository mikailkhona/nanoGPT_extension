2023-07-27 13:30:27,379 INFO    StreamThr :21127 [internal.py:wandb_internal():86] W&B internal server running at pid: 21127, started at: 2023-07-27 13:30:27.378886
2023-07-27 13:30:27,380 DEBUG   HandlerThread:21127 [handler.py:handle_request():144] handle_request: status
2023-07-27 13:30:27,382 INFO    WriterThread:21127 [datastore.py:open_for_write():85] open: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/run-2ruau35a.wandb
2023-07-27 13:30:27,383 DEBUG   SenderThread:21127 [sender.py:send():379] send: header
2023-07-27 13:30:27,383 DEBUG   SenderThread:21127 [sender.py:send():379] send: run
2023-07-27 13:30:27,879 INFO    SenderThread:21127 [dir_watcher.py:__init__():211] watching files in: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/files
2023-07-27 13:30:27,879 INFO    SenderThread:21127 [sender.py:_start_run_threads():1122] run started: 2ruau35a with start time 1690479027.378543
2023-07-27 13:30:27,879 DEBUG   SenderThread:21127 [sender.py:send_request():406] send_request: summary_record
2023-07-27 13:30:27,879 INFO    SenderThread:21127 [sender.py:_save_file():1376] saving file wandb-summary.json with policy end
2023-07-27 13:30:27,883 DEBUG   HandlerThread:21127 [handler.py:handle_request():144] handle_request: check_version
2023-07-27 13:30:27,884 DEBUG   SenderThread:21127 [sender.py:send_request():406] send_request: check_version
2023-07-27 13:30:27,968 DEBUG   HandlerThread:21127 [handler.py:handle_request():144] handle_request: run_start
2023-07-27 13:30:27,972 DEBUG   HandlerThread:21127 [system_info.py:__init__():31] System info init
2023-07-27 13:30:27,972 DEBUG   HandlerThread:21127 [system_info.py:__init__():46] System info init done
2023-07-27 13:30:27,972 INFO    HandlerThread:21127 [system_monitor.py:start():181] Starting system monitor
2023-07-27 13:30:27,972 INFO    SystemMonitor:21127 [system_monitor.py:_start():145] Starting system asset monitoring threads
2023-07-27 13:30:27,973 INFO    HandlerThread:21127 [system_monitor.py:probe():201] Collecting system info
2023-07-27 13:30:27,974 INFO    SystemMonitor:21127 [interfaces.py:start():190] Started cpu monitoring
2023-07-27 13:30:27,975 INFO    SystemMonitor:21127 [interfaces.py:start():190] Started disk monitoring
2023-07-27 13:30:27,975 INFO    SystemMonitor:21127 [interfaces.py:start():190] Started gpu monitoring
2023-07-27 13:30:27,976 INFO    SystemMonitor:21127 [interfaces.py:start():190] Started memory monitoring
2023-07-27 13:30:27,976 INFO    SystemMonitor:21127 [interfaces.py:start():190] Started network monitoring
2023-07-27 13:30:28,011 DEBUG   HandlerThread:21127 [system_info.py:probe():195] Probing system
2023-07-27 13:30:28,012 DEBUG   HandlerThread:21127 [system_info.py:_probe_git():180] Probing git
2023-07-27 13:30:28,016 DEBUG   HandlerThread:21127 [system_info.py:_probe_git():188] Probing git done
2023-07-27 13:30:28,016 DEBUG   HandlerThread:21127 [system_info.py:probe():240] Probing system done
2023-07-27 13:30:28,016 DEBUG   HandlerThread:21127 [system_monitor.py:probe():210] {'os': 'Linux-5.19.0-46-generic-x86_64-with-glibc2.35', 'python': '3.10.6', 'heartbeatAt': '2023-07-27T17:30:28.011195', 'startedAt': '2023-07-27T17:30:27.375722', 'docker': None, 'cuda': None, 'args': (), 'state': 'running', 'program': '/home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/train_ntt.py', 'codePath': 'train_ntt.py', 'git': {'remote': 'git@github.com:mikailkhona/nanoGPT_extension.git', 'commit': 'd6d0d4b745baefa89392e7c8db5f729ac2e1bc4d'}, 'email': None, 'root': '/home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension', 'host': 'dl', 'username': 'bizon', 'executable': '/usr/bin/python3', 'cpu_count': 32, 'cpu_count_logical': 64, 'cpu_freq': {'current': 2.6866093749999993, 'min': 1800.0, 'max': 3600.0}, 'cpu_freq_per_core': [{'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 2.7, 'min': 1800.0, 'max': 3600.0}, {'current': 1.802, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.913, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 2.405, 'min': 1800.0, 'max': 3600.0}, {'current': 1.911, 'min': 1800.0, 'max': 3600.0}, {'current': 1.919, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.919, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.917, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 2.315, 'min': 1800.0, 'max': 3600.0}, {'current': 1.917, 'min': 1800.0, 'max': 3600.0}, {'current': 1.873, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 2.66, 'min': 1800.0, 'max': 3600.0}, {'current': 1.871, 'min': 1800.0, 'max': 3600.0}, {'current': 1.916, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 2.397, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 2.261, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 2.213, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.878, 'min': 1800.0, 'max': 3600.0}, {'current': 1.876, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.834, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}, {'current': 1.917, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 3.6, 'min': 1800.0, 'max': 3600.0}, {'current': 2.399, 'min': 1800.0, 'max': 3600.0}, {'current': 1.8, 'min': 1800.0, 'max': 3600.0}], 'disk': {'total': 1876.1108436584473, 'used': 587.6454849243164}, 'gpu': 'NVIDIA RTX A6000', 'gpu_count': 6, 'gpu_devices': [{'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}, {'name': 'NVIDIA RTX A6000', 'memory_total': 51527024640}], 'memory': {'total': 503.52610778808594}}
2023-07-27 13:30:28,017 INFO    HandlerThread:21127 [system_monitor.py:probe():211] Finished collecting system info
2023-07-27 13:30:28,017 INFO    HandlerThread:21127 [system_monitor.py:probe():214] Publishing system info
2023-07-27 13:30:28,017 DEBUG   HandlerThread:21127 [system_info.py:_save_pip():51] Saving list of pip packages installed into the current environment
2023-07-27 13:30:28,017 DEBUG   HandlerThread:21127 [system_info.py:_save_pip():67] Saving pip packages done
2023-07-27 13:30:28,018 INFO    HandlerThread:21127 [system_monitor.py:probe():216] Finished publishing system info
2023-07-27 13:30:28,881 INFO    Thread-12 :21127 [dir_watcher.py:_on_file_created():272] file/dir created: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/files/wandb-summary.json
2023-07-27 13:30:28,881 INFO    Thread-12 :21127 [dir_watcher.py:_on_file_created():272] file/dir created: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/files/wandb-metadata.json
2023-07-27 13:30:28,882 INFO    Thread-12 :21127 [dir_watcher.py:_on_file_created():272] file/dir created: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/files/requirements.txt
2023-07-27 13:30:28,884 INFO    WriterThread:21127 [datastore.py:close():294] close: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/run-2ruau35a.wandb
2023-07-27 13:30:28,965 INFO    SenderThread:21127 [sender.py:finish():1552] shutting down sender
2023-07-27 13:30:28,966 INFO    SenderThread:21127 [dir_watcher.py:finish():359] shutting down directory watcher
2023-07-27 13:30:29,882 INFO    SenderThread:21127 [dir_watcher.py:finish():389] scan: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/files
2023-07-27 13:30:29,882 INFO    SenderThread:21127 [dir_watcher.py:finish():403] scan save: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/files/wandb-summary.json wandb-summary.json
2023-07-27 13:30:29,883 INFO    SenderThread:21127 [dir_watcher.py:finish():403] scan save: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/files/wandb-metadata.json wandb-metadata.json
2023-07-27 13:30:29,883 INFO    SenderThread:21127 [dir_watcher.py:finish():403] scan save: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/files/config.yaml config.yaml
2023-07-27 13:30:29,883 INFO    SenderThread:21127 [dir_watcher.py:finish():403] scan save: /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/files/requirements.txt requirements.txt
2023-07-27 13:30:29,883 INFO    SenderThread:21127 [file_pusher.py:finish():159] shutting down file pusher
2023-07-27 13:30:29,883 INFO    SenderThread:21127 [file_pusher.py:join():164] waiting for file pusher
2023-07-27 13:30:30,222 INFO    wandb-upload_0:21127 [upload_job.py:push():131] Uploaded file /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/files/wandb-summary.json
2023-07-27 13:30:30,351 INFO    wandb-upload_3:21127 [upload_job.py:push():131] Uploaded file /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/files/requirements.txt
2023-07-27 13:30:30,384 INFO    wandb-upload_2:21127 [upload_job.py:push():131] Uploaded file /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/files/config.yaml
2023-07-27 13:30:30,461 INFO    wandb-upload_1:21127 [upload_job.py:push():131] Uploaded file /home/bizon/temp-cot/Causal_graphs_chain_of_thought/nanoGPT_extension/wandb/run-20230727_133027-2ruau35a/files/wandb-metadata.json
2023-07-27 13:30:31,126 ERROR   StreamThr :21127 [internal.py:wandb_internal():174] Thread HandlerThread:
Traceback (most recent call last):
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py", line 49, in run
    self._run()
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal_util.py", line 100, in _run
    self._process(record)
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/internal.py", line 279, in _process
    self._hm.handle(record)
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/handler.py", line 136, in handle
    handler(record)
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/handler.py", line 146, in handle_request
    handler(record)
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/handler.py", line 708, in handle_request_run_start
    self._tb_watcher = tb_watcher.TBWatcher(
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/internal/tb_watcher.py", line 126, in __init__
    wandb.tensorboard.reset_state()
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/lib/lazyloader.py", line 58, in __getattr__
    module = self._load()
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/sdk/lib/lazyloader.py", line 33, in _load
    module = importlib.import_module(self.__name__)
  File "/usr/lib/python3.10/importlib/__init__.py", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1050, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1027, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1006, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 688, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 883, in exec_module
  File "<frozen importlib._bootstrap>", line 241, in _call_with_frames_removed
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/integration/tensorboard/__init__.py", line 3, in <module>
    from .log import _log, log, reset_state, tf_summary_to_dict  # noqa: F401
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/integration/tensorboard/log.py", line 35, in <module>
    Summary = pb.Summary if pb else None
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/util.py", line 204, in __getattribute__
    state.load()
  File "/home/bizon/.local/lib/python3.10/site-packages/wandb/util.py", line 197, in load
    self.module.__spec__.loader.exec_module(self.module)
  File "/usr/local/lib/python3.10/dist-packages/tensorboard/compat/proto/summary_pb2.py", line 17, in <module>
    from tensorboard.compat.proto import tensor_pb2 as tensorboard_dot_compat_dot_proto_dot_tensor__pb2
  File "/usr/local/lib/python3.10/dist-packages/tensorboard/compat/proto/tensor_pb2.py", line 16, in <module>
    from tensorboard.compat.proto import resource_handle_pb2 as tensorboard_dot_compat_dot_proto_dot_resource__handle__pb2
  File "/usr/local/lib/python3.10/dist-packages/tensorboard/compat/proto/resource_handle_pb2.py", line 16, in <module>
    from tensorboard.compat.proto import tensor_shape_pb2 as tensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2
  File "/usr/local/lib/python3.10/dist-packages/tensorboard/compat/proto/tensor_shape_pb2.py", line 36, in <module>
    _descriptor.FieldDescriptor(
  File "/home/bizon/.local/lib/python3.10/site-packages/google/protobuf/descriptor.py", line 561, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
TypeError: Descriptors cannot not be created directly.
If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.
If you cannot immediately regenerate your protos, some other possible workarounds are:
 1. Downgrade the protobuf package to 3.20.x or lower.
 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).

More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates
